{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d48237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import feature\n",
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cba714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_image(img):\n",
    "    features=feature.hog(img,orientations=9,pixels_per_cell=(10,10),cells_per_block=(2,2),transform_sqrt=True,block_norm=\"L1\")\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_split(path):\n",
    "    imgp=list(paths.list_images(path))\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    for ip in imgp:\n",
    "        label=ip.split(os.path.sep)[-2]\n",
    "        img=cv2.imread(ip)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img,(200,200))\n",
    "        img=cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        features=quantify_image(img)\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "    return (np.array(data),np.array(labels))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4bddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trp=r\"spiral\\spiral\\training\"\n",
    "tep=r\"spiral\\spiral\\testing\"\n",
    "(xtrain,ytrain)=load_split(trp)\n",
    "(xtest,ytest)=load_split(tep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa1931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 12996) (72,)\n"
     ]
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "ytrain=le.fit_transform(ytrain)\n",
    "ytest=le.transform(ytest)\n",
    "print(xtrain.shape,ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41dca246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53ae292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testp=list(paths.list_images(tep))\n",
    "idxs=np.arange(0,len(testp))\n",
    "idxs=np.random.choice(idxs,size=(25,),replace=False)\n",
    "images=[]\n",
    "for i in idxs:\n",
    "    image=cv2.imread(testp[i])\n",
    "    op=image.copy()\n",
    "    op=cv2.resize(op,(128,128))\n",
    "    img=image\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img=cv2.resize(img,(200,200))\n",
    "    img=cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    features=quantify_image(img)\n",
    "    preds=model.predict([features])\n",
    "    label=le.inverse_transform(preds)[0]\n",
    "    color=(0,255,0) if label==\"healthy\" else (0,0,255)\n",
    "    cv2.putText(op,label,(3,20),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
    "    images.append(op)\n",
    "montage=build_montages(images,(128,128),(5,5))[0]\n",
    "cv2.imshow(\"ahahaa\",montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc0e8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  1  3 12]\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(xtest)\n",
    "cm=confusion_matrix(ytest,predictions).flatten()\n",
    "print(cm)\n",
    "(tn,fp,fn,tp)=cm\n",
    "acc=(tp+tn)/float(cm.sum())\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32262d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26d80942",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('modelRF.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e455529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parkinson\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('test1.jpg')\n",
    "op=image.copy()\n",
    "op=cv2.resize(op,(128,128))\n",
    "img=image\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.resize(img,(200,200))\n",
    "img=cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "features=quantify_image(img)\n",
    "preds=model.predict([features])\n",
    "label=le.inverse_transform(preds)[0]\n",
    "color=(0,255,0) if label==\"healthy\" else (0,0,255)\n",
    "cv2.putText(op,label,(3,20),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
    "print(label)\n",
    "cv2.imshow(\"hello\",op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a260a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
